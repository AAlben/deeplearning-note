### [Question]

#### 线性代数部分

1.矩阵的分解
- 特征分解
- 奇异值分解
- 都一知半解


2.行列式 → 主成分分析PCA
- 对矩阵进行有损压缩 → 编码(压缩) + 解码(还原)
- 诸多设想 + 限制
 	- 要有唯一解 → D的所有列向量，都有单位范数
 	- 使编码问题简单 → D的列向量，彼此正交
 	- 最小化距离 → 使用平方L2范数
 	- 微积分求最优化问题


-----

#### 概率部分

1.大方向上，概率和逻辑是有区别的，什么区别？
- 概率：量化概率分布中的不确定性
- 逻辑：不确定性存在情况下进行推理

2.不确定性的具体情况？作用是什么？
- 目前了解到，有3种。
- 内部随机、非对称的随机、与可能导致的随机

3.概率的类型，更深入一点的区别
- 频率派概率：根据玩家的牌，预测该人获胜概率 | 可进行反复测验
- 贝叶斯概率：医生根据病人的症状，预测患病的概率 | 不可反复重复测验

4.由随机变量开始，随机变量 → 概率分布 → 联合概率分布
- 随机变量 → 描述可随机取不同值的状态的描述
- 概率分布 → 随机变量在每一个可能取到的状态的可能性大小
- 联合概率分布 → 多个随机变量的概率分布

5.独立性 + 条件独立性
- 可写成因子的乘积形式
- 最终：代表一种特性的状态，有助于计算时使用

6.期望、方差、标准差、协方差、协方差矩阵
- 协方差与独立与否之间的关系

7.概率分布，及类型
- 常用的概率分布
- 高斯分布 → 正态分布 → 中心极限定理 → 这么热衷于使用这个分布模型的原因？
- 高斯混合模型

8.信息论
- 信息论的哪些思想被借鉴到了深度学习中？
- 对消息进行最优编码设计
- 计算消息的期望长度
- 可使用多种不同的编码机制
- 特定的概率分布
- 映射到描述概率分布或者量化概率分布之间的相似性

### [理解]

1.一切从概率分布开始 → 有了线性与否，独立与否的特性 → 有了概率分布的诸多典型模型 → 还代入到矩阵中去，进行计算 and more

2.信息论这块，不明所以 + 不明觉厉
