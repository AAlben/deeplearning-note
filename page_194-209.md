### [归纳]

#### 深度前馈网络部分

**1.神经网络的输出单元特点**


1)神经网络可以推广到我们希望的几乎任何种类的输出层

2)最大似然原则则是在设计好的代价函数方面提供了知道

3)多峰回归 + 高斯混合 → 在语音生成模型 + 物理运动这两方面特别有效


**2.如何选择隐藏单元的类型？**

- 整流线性单元：隐藏单元极好的默认选择
- 其他隐藏单元

新技术：代表新的隐藏单元的激活函数

只有被证明能够提供显著改进时才会被发布


**3.如何进行架构设计？**

- 架构设计指的是什么？

1)该模型应该具有多少个单元

2)单元与单元之间应该如何连接

- 架构应该考虑什么？

1)网络的深度

2)每一层的宽度

3)理想状态：

	只有一个隐藏层，且适应训练集
	每一层也可以由更少的单元数 + 更少的参数组成
	且保证泛化效果

- 万能近似性质：神经网络可以推广到我们希望的几乎任何种类的输出层

1)线性模型：仅能学习出线性函数；但是往往希望学习的是非线性函数

2)具有隐藏层的前馈网络提供了一种万能近似框架

3)无论试图学习什么参数，MLP一定能够表示这个函数

4)但是这与没有免费的午餐定理有所冲突

	不存在万能的过程，既能够验证训练集上的特殊样本
	又能够选择一个函数来扩张到训练集上没有的点

5)所以，找到恰当的深度值，尤其重要
	浅层模型：需要的隐藏单元的数量级是指数级
	深度和模型效率是比如相关联的
	深层模型：在泛化性上表现良好


**4.反向传播**

- 前馈神经网络：是输入x经由一层层向前流动，最终输出y；即前向传播
- 反向传播：允许来自代价函数的信息通过网络向后流动 → 以便计算梯度
- 微积分中的链式法则：不仅仅使用与向量，任意维度的张量也可适用
- 递归使用链式法则来实现反向传播：针对于重复计算，若次次计算，有重复冗余的计算开销；若将表达式存储起来，则有内存开销
