### [问题]

#### 直面配分函数部分

**1.配分函数**

- 配分函数的应用场景？

许多概率模型由一个未归一化的概率分布定义，且必须通过除以配分函数来归一化，以获得一个有效的概率分布

配分函数是对未归一化概率所有状态的积分或求和

会出现配分函数难以计算的问题

**2.配分函数的具体应用场景**

- 对数似然梯度

通过最大似然学习无向模型有特别困难的点：配分函数依赖于参数

对数似然相对于参数的梯度具有一项对应于配分函数的梯度

正相分解 + 负相分解

- 随机最大似然和对比散度

会出现求解中，每次计算梯度时，都需要磨合随机初始化的一组马尔科夫链的情况

内循环中磨合马尔科夫链的计算代价过高

最大化似然的MCMC方法可视为两种力之间的平衡

1. 一种力拉高数据出现的模型分布

2. 一种力拉低模型采样出现时的模型分布

- 负相

负相涉及从模型分布中抽样

在模型找信任度很高的点

但是又减少了这些点的概率？？

正相会帮助找到信任度很高的点吗？？

- 如何减少磨合步骤？

初始化马尔科夫链为一个非常接近模型分布的分布，有助于减少磨合步骤

- 伪似然

蒙特卡罗近似配分函数及其梯度需要直接处理配分函数 → 计算代价很高

也可通过不需要计算配分函数的模型来绕开这个问题

伪似然正式基于条件概率可以采用这种基于比率的形式，可在没有配分函数的情况下进行计算

- 广义伪似然估计

权衡计算复杂度和最大似然表现的偏差

广义伪似然估计与似然估计的效果孰好孰坏？

分场景，在如下场景中广义伪似然估计的效果比最大似然要好

1. 填充少量的缺失值

2. 当数据具有规则结构，建立一个索引集，寻找具有最重要相关性质，且略去相关性可忽略的变量

缺点：

1. 不能与仅在p(x)上提供下界的其他近似一起使用，如变分推断

2. 伪似然方法难应用于诸如深度玻尔兹曼机的深度模型

计算代价：

伪似然比SML在每个梯度步骤中的计算代价要大得多

但是，若每个样本只计算一个随机选择的条件的话，这个计算代价可以接受

- 得分分配

所使用的策略：最小化模型对数密度和数据对数密度关于输入的导数之间的平方差期望

- 比率匹配

将得分匹配的基本想法扩展到离散数据的方法