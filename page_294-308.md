### [问题]

#### 深度模型中的优化问题部分

**1.牛顿法**

- 神经网络中最广泛使用的二阶方法：牛顿法

- 牛顿法解决了哪些问题？

二阶方法 → 一阶的导数？

- 牛顿法有哪些问题？

1)会受到目标函数的某些特征带来的挑战

2)每次训练迭代，导致参数的改变，需要进行重新计算

导致 → 只有参数很少的网络才能在实际中用牛顿法来训练

还有，当目标函数的表面非常凸，如有鞍点的情况 → 使用牛顿法会有问题


**2.共轭梯度**

- 最速下降方法有什么弱点？

- 线搜索是什么？

- 共轭梯度解决哪些问题？

在当前梯度方向下降到极小值时，必须重新最小化之前在梯度方向上的目标 → 会撤销之前线搜索方向上取得的进展

- 如何解决？

寻求一个和先前线搜索方向共轭的搜索方向

- 批方法？

- 非线性共轭梯度都做什么？

对线性共轭梯度算法的查缺补漏？

**3.优化策略和元算法**

- 批标准化解决了哪些问题？

试图解决训练模型深的问题 → 深的模型会带来多个函数或层的组合

答案为使用批标准化方法

- 批标准化的好处是什么？

1)恢复了零均值 + 单位方差的特性

2)保持着单位高斯

3)减少每次更新所带来的影响

4)使得模型的学习更容易

- 除了批标准化之外还有若干其他的方法 + 策略

1)坐标下降

2)监督预训练：贪心监督预训练

3)延拓法

